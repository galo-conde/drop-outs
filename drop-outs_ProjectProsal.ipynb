{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectProsal_GroupGHJN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP_DcgAsCgLb"
      },
      "source": [
        "# Project Proposal - Group GHJN\n",
        "\n",
        "**Authors** \n",
        "\n",
        "Galo (g_c273)\n",
        "\n",
        "Husain (haa38)\n",
        "\n",
        "Jason (jlm573)\n",
        "\n",
        "Noah (n_s122) \n",
        "<br/><br/>\n",
        "\n",
        "## Proposal\n",
        "\n",
        "There is little contest refuting the notion that decreasing educational funding negatively impacts the success of students. Public schools rely on a combination of local, state, and federal sources of funding their educational programs. These allocations change year to year depending on the current political climate and economic circumstances. Our overall objective is to design and evaluate predictions of which educational program's funding change will have the biggest impact on drop-out rates. \n",
        "<br/><br/>\n",
        "\n",
        "**Data** :\n",
        "\n",
        "In this project we will use Common Core of Data (CCD) provided by the U.S. Department of Education. The model will be designed using the National Public Education Financial Survey Data and State Dropout and Completion Data from year 2002-2007. We will test the predictive qualites of the model against 2008-2010 to evalute the validity of our predictions.\n",
        "A possible obstacle in creating the model will be missing data due to the creation or discountinuation of educational programs year to year. Additional complications may arise when testing the model against data from years correspinding to the unsual economic circumstances of the Great Recession. \n",
        "<br/><br/>\n",
        "\n",
        "**Project Goal** : \n",
        "This project hopes to reveal the impact of individual educational programs have on gradutaion rates in order to better protect their budget allocation when face with education funding cuts. \n",
        "\n",
        "--\n",
        "\n",
        " \n",
        "**Abstract** : tbd\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "tbd\n",
        "\n",
        "## Problem Statement \n",
        "* Give a clear and complete statement of the problem. \n",
        "  What is the benchmark you are using.  Why?  Where does the data come from, what are its characteristics? \n",
        "* Include informal success measures (e.g. accuracy on cross-validated data, without specifying ROC or precision/recall etc) that you planned to use.\n",
        "* What do you hope to achieve? \n",
        "\n",
        "### Related Work\n",
        "\n",
        "* Include background material as appropriate: who cares about this problem, what impact it has, what implications better solutions might have.\n",
        "* Included a brief summary of any related work you know about.\n",
        "* Benchmark implementations - see [paperswithcode.com](paperswithcode.com) as a good start \n",
        "\n",
        "## Data Management \n",
        "\n",
        "In this section you should address the questions of interest and interpret the results in terms of the questions of interest you proposed. (1-5 pages, including relevant tables and figures, please adjust your figures to appropriate sizes).\n",
        "\n",
        "- Describe how did you evaluate your solution\n",
        "- What evaluation metrics did you use?\n",
        "- Describe a baseline system\n",
        "- How much did your system outperform the baseline?\n",
        "- Were there other systems evaluated on the same dataset? How did your system do in comparison to theirs?\n",
        "- Show graphs/tables with results\n",
        "- Error analysis\n",
        "- Suggestions for future improvements\n",
        "\n",
        "Description of the dataset (dimensions, names of variables with their description)\n",
        "\n",
        "### Data Gathering\n",
        "\n",
        "Answer the questions from *Motivation* (Sec 3.1.) *Composition* (Sec 3.2), and *Collection* (Sec 3.3) of the [Datasheets For Datasets](https://arxiv.org/abs/1803.09010) paper here. \n",
        "* If benchmarks, describe the data in details.\n",
        "* If data collections, justify your methods in terms of data statement. \n",
        "\n",
        "What Data Acquisition have you used.  Why? \n",
        "(usually algorithms, or data cleaning or wrangling approaches). \n",
        "\n",
        "Justify your methods in terms of the problem statement. What did you consider but *not* use? In particular, be sure to include every method you tried, even if it didn't \"work\". When describing methods that didn't work, make clear how they failed and any evaluation metrics you used to decide so. How was that a data-driven decision? \n",
        "\n",
        "### Data Pre-processing, Cleaning, Labeling, and Maintenance \n",
        "\n",
        "What Cleaning, and Processing Tools have you used.  Why? \n",
        "* Answer the questions from 3.4 **Preprocessing/cleaning/labeling** of the [Datasheets For Datasets](https://arxiv.org/abs/1803.09010) paper here. \n",
        "\n",
        "### Exploratory Data Analysis \n",
        "\n",
        "* Describe the methods you explored (usually algorithms, or data wrangling approaches). \n",
        "* Justify your methods in terms of the problem statement. \n",
        "* What did you consider but *not* use? In particular, be sure to include every method you tried, even if it didn't \"work\". \n",
        "**NOTE:** Move from .md to .ipynb format when you plan to show EDA (either project proposal or midterm checkpoint)\n",
        "\n",
        "\n",
        "## Machine Learning Approaches\n",
        "\n",
        "In this section, you could describe the methods you used in your analysis. For example, if you are doing classifications, you could introduce the methods like logistic regression, discriminant analysis, support vector machines. You don't have to write formulas if you don't want to do so. It is fine to describe the methods in words. This section basically is a description of the methodologies that you have used for analyzing your data. (up to 2pages)\n",
        "Describe the choice of Machine Learning Tool.  Refer ro related work, if applicable.  \n",
        "\n",
        "* Evaluate a primary model and in addition a \"baseline\" model. \n",
        "  * The baseline is typically the simplest model that's applicable to that data problem\n",
        "    * Naive Bayes for classification\n",
        "\t* K-means on raw feature data for clustering.\n",
        "* Evaluate state-of-art model \n",
        "  * Research gitHuib, paperswithcode, Kaggle and similar. \n",
        "  * If not applicable, talk to the instructor.  \n",
        "  \n",
        "**Hint** Goal is to have some sort of baseline evaluation by Nov 11th checkpoint to establish a scale by which to measure your project's performance. Compare the performance of your baseline model and primary model and explain the differences.\n",
        "\n",
        "** This is where all the methods you have tried go, including state-of-art if any **\n",
        "\n",
        "### Describe the ML methods that you used and the reasons for their choice. \n",
        "What is the family of machine learnign algorithms you are using and why? \n",
        "* Supervised or Unsupervised?\n",
        "* Regression or classification?\n",
        "\n",
        "### Justify ML algorithms in terms of the problem itself and the methods you want to use. \n",
        "* How did you employ them? \n",
        "* What features worked well and what didn't?\n",
        "* Provide documentation for integration  \n",
        "\n",
        "### Tools and Infrastructure Tried and Not Used\n",
        "\n",
        "Describe any tools and infrastruicture that you tried and ended up not using.\n",
        "What was the problem? \n",
        "Describe infrastructure used. \n",
        "\n",
        "## Experiments\n",
        "\n",
        "Give a detailed summary of the results of your work.\n",
        "\n",
        " * Setup - Here is where you specify the exact performance measures you used.  \n",
        "   * Describe the data used in experiment for presenting dataset: Datasheets for Dataset template \n",
        "   * Describe your accuracy or quality measure, and your performance (runtime or throughput) measure. \n",
        "   \n",
        " * Please use visualizations whenever possible. Include links to interactive visualizations if you built them. \n",
        " \n",
        " * You can also submit a separated notebook as an appendix to your report if that makes the visualization/interaction task easier. \n",
        "   * It would be reasonable to submit your report as a notebook, but please make sure it runs on one of the two standard environments, and that you include any required files. \n",
        "\n",
        "## Conclusion\n",
        "In this section give a high-level summary of your results. If the reader only reads one section of the report, this one should be it, and it should be self-contained.  You can refer back to the Experiments Section for elaborations. This section should be less than a page. In particular emphasize any results that were surprising.\n",
        "\n",
        "\n",
        "## References\n",
        "List the references that cited in your project.\n",
        "\n",
        "## Appendix## \n",
        "\n",
        "Explain the contributions of each member to the project. Include all supporting materials, e.g., additional figures/tables, Python code technical derivations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogKwM5XmCjiU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}